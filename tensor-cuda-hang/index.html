<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=5" name="viewport"><meta content="yes" name="mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><script>(()=>{let r="/cnfonts.js",n=document,e=n.createElement("link");e.rel="stylesheet",e.href="/fontchan/jBKCaHQX.css",e.blocking="render",e.onerror=()=>{var e=n.createElement("script");e.src=r,e.onload=()=>$fontchan.injectCss(),n.head.appendChild(e)},n.head.appendChild(e),"serviceWorker"in navigator&&navigator.serviceWorker.register(r,{scope:"/"}).then(e=>e.update())})()</script><title>Debug a 'torch.tensor(1).cuda()' hanging</title><meta itemprop="title" content="Debug a 'torch.tensor(1).cuda()' hanging - hsfzxjy 的博客"><meta itemprop="og:title" content="Debug a 'torch.tensor(1).cuda()' hanging - hsfzxjy 的博客"><meta itemprop="image" content="https://i.hsfzxjy.site/avatar-for-hsfzxjy.jpg"><meta itemprop="og:image" content="https://i.hsfzxjy.site/avatar-for-hsfzxjy.jpg"><meta itemprop="description" content="Today a user of our GPU cluster ran into a problem where ..."><meta itemprop="og:type" content="website"><link rel="stylesheet" href="/dist/css/style.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/rss+xml" href="/rss.xml"></head><body><nav class="nav"><span class="nav__toggler"><span class="nav__toggler-bar bar1"></span><span class="nav__toggler-bar bar2"></span><span class="nav__toggler-bar bar3"></span></span><span class="nav__core"><div class="nav__logo"><img src="/avatar.webp" loading="lazy"></div><a href="/" lang="zh" class="nav__brand">hsfzxjy</a></span><span class="nav__togglerClose"><span class="nav__togglerClose-circle"></span><span class="nav__togglerClose-bar bar1"></span><span class="nav__togglerClose-bar bar2"></span></span><div class="nav__pathIndicator"><a href="/categories/Tech/">Tech</a></div></nav><main class="mainContainer"><div lang="en" class="post post-page"><h1 lang="en" class="post__title">Debug a 'torch.tensor(1).cuda()' hanging</h1><div class="post__meta font__ui">2021-12-14 | <span class="post__meta-categories"><a href="/categories/Tech/">Tech</a></span></div><div class="post__content font__body"><p>Today a user of our GPU cluster ran into a problem where executing <code>python -c &#39;import torch; torch.tensor(1).cuda()</code> would hang forever and could not be killed. The problem occured on a rather old Docker image (with <code>torch == 0.4.0</code>), and would disappear if newer images were used. It was caused by some far less known coincidents, which surprised me and I want to share in this post.</p><h2 id="the-problem">The Problem</h2><p>The hanging program is spawned by following command:</p><div class="gk-code hljs" data-gk-id="BLOCK1"><div class="gk-code-display"><pre><span class="line">/usr/bin/docker run --<span class="hljs-built_in">rm</span> -u 1457:1457 \</span><br><span class="line">    --gpus <span class="hljs-string">&#x27;&quot;device=&#x27;</span>0,1,2,3<span class="hljs-string">&#x27;&quot;&#x27;</span> \</span><br><span class="line">    -v /ghome/username:/ghome/username -v /gdata/username:/gdata/username \</span><br><span class="line">    -it --ipc=host --shm-size 64G \</span><br><span class="line">    -v /gdata1/username:/gdata1/username -v /gdata2/username:/gdata2/username \</span><br><span class="line">    -e HOME=/ghome/username \</span><br><span class="line">    -m 48G --memory-swap 48G --cpus 5 \</span><br><span class="line">    --name username2 \</span><br><span class="line">    bit:5000/deepo_9 \</span><br><span class="line">    python3 -c <span class="hljs-string">&#x27;import torch; torch.tensor(1).cuda()&#x27;</span></span><br></pre></div></div><p class="par">the Docker image <code>bit:5000/deepo_9</code> he used was built with CUDA-9, while the host has multiple 1080Ti GPU cards and CUDA upgraded to 11.4. Looks like there’s some binary incompatibility, considering the fact that the problem would gone with newer images.</p><h2 id="step-1-find-out-the-incorrect-arguments">Step 1: Find out the incorrect arguments</h2><p>But firstly, I have to confirm that there is no mis-configuration. Programs stuck from time to time on our cluster, and some were caused by mis-configuration from users, such as incorrect <code>docker run</code> arguments. I then decided to take a try on a most simplified version of command</p><div class="gk-code hljs" data-gk-id="BLOCK2"><div class="gk-code-display"><pre><span class="line">/usr/bin/docker run --<span class="hljs-built_in">rm</span> -u 1457:1457 \</span><br><span class="line">    --gpus <span class="hljs-string">&#x27;&quot;device=&#x27;</span>0,1,2,3<span class="hljs-string">&#x27;&quot;&#x27;</span> \</span><br><span class="line">    --name username2 \</span><br><span class="line">    bit:5000/deepo_9 \</span><br><span class="line">    python3 -c <span class="hljs-string">&#x27;import torch; torch.tensor(1).cuda()&#x27;</span></span><br></pre></div></div><p class="par">This command worked just fine, which suggests that the problem is from some combination of other arguments.</p><p>I should find out what the combination is. For which I progressively added back the arguments, one at a time. And finally it turned out that <code>-v /ghome/username:/ghome/username</code> and <code>-e HOME=/ghome/username</code> mutually caused the stuck.</p><h2 id="step-2-find-out-the-trapped-io">Step 2: Find out the trapped IO</h2><p class="noindent">The above finding offers two hints:</p><ol><li>Something performs IO under <code>$HOME</code>;</li><li>Such IO works well with default setting <code>HOME=/</code>, but stucks with <code>HOME=/ghome/username</code>.</li></ol><p class="par">So what’s different between <code>/</code> and <code>/ghome/username</code>? If you write under both directories, the previous one would be resolved into the container FS layer, while the latter to an external volume, with NFS as underlying FS. It might be a special IO operation that differs on the two file systems.</p><p>To find out the operation, I attached <code>strace</code> to the python process, which would spy and print out all syscalls the program invoked. The logs rolled by and eventually stopped at following lines</p><div class="gk-code hljs" data-gk-id="BLOCK3"><div class="gk-code-display"><pre><span class="line">open(&quot;/ghome/username/.nv/ComputeCache/index&quot;, O_RDWR) = 30</span><br><span class="line">clock_gettime(CLOCK_MONOTONIC_RAW, {tv_sec=551059, tv_nsec=515612618}) = 0</span><br><span class="line">fcntl(30, F_SETLK, {l_type=F_RDLCK, l_whence=SEEK_SET, l_start=0, l_len=0}) = ?</span><br><span class="line">+++ killed by SIGKILL +++</span><br></pre></div></div><p class="par">Now we know the culprit is an <code>flock</code> attempt on file <code>/ghome/username/.nv/ComputeCache/index</code>, residing on NFS. NFS does not co-operate well with file locks, which typically shows up as hanging a program.</p><h2 id="step-3-whos-performing-the-io">Step 3: Who’s performing the IO?</h2><p>Now it’s a bit weird. The python process executes merely nothing, and I cannot figure out where the IO came from. I hence typed <code>.nv/ComputeCache</code> in Google inquiring for answer. The first entry popped up was <a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/cuda-pro-tip-understand-fat-binaries-jit-caching/">CUDA Pro Tip: Understand Fat Binaries and JIT Caching</a>, where I read the following</p><blockquote><p>nvcc, the CUDA compiler driver, uses a two-stage compilation model. The first stage compiles source device code to PTX virtual assembly, and the second stage compiles the PTX to binary code for the target architecture. The CUDA driver can execute the second stage compilation at run time, compiling the PTX virtual assembly “Just In Time” to run it. This JIT compilation can cause delay at application start-up time (or more accurately, CUDA context creation time). CUDA uses two approaches to mitigate start-up overhead on JIT compilation: fat binaries and JIT caching.</p><p class="nomargin">[…]</p><p class="nomargin"><code>CUDA_CACHE_PATH</code> specifies the directory location of compute cache files; the default values are:</p><ul><li>[…]</li><li>on Linux, <code>~/.nv/ComputeCache</code></li></ul></blockquote><p class="par">It turns out that CUDA runtime itself is the executer. Either no fat binaries found or fat binaries incompatibility in PyTorch triggers the second approach JIT caching. The docs also mentions a potential problem (similar to what we have met) and corresponding solution</p><blockquote><h3 id="cache-stored-on-a-slow-network-share">Cache stored on a Slow Network Share</h3><p>On Linux, the default location of the CUDA JIT cache is in your home directory. On clusters, it is not uncommon to mount home directories with relatively poor performance to the compute nodes (by using the Lustre file system for scratch space, but only NFS for the home directory, for example). We have seen cases where this relatively slow connection to the home directory (and thus the JIT cache) resulted in very long application start-up times when the application was not built with code for the right SM version. Even more confusing, start-up time can vary from node to node due to intricacies of the NFS set up.</p><p>In this situation, it is best to build the application to avoid JIT entirely, and alternatively, to set <code>CUDA_CACHE_PATH</code> to point to a location on a fast file system.</p></blockquote><h2 id="epilogue">Epilogue</h2><p>So it was actually a less known (at least by me) feature of CUDA runtime, coincides with a rare usecase (NFS as home directory). Surprising results, but also teaches me some interesting facts beyond the user space boundary.</p><p>I’ve tried to figure out why newer images just works well. They won’t trigger the JIT caching, which suggests pre-compiled fat binaries are compatible with the current arch. I compared the binaries by dumping information using <code>cuobjdump</code>, but noticed nothing (or just I am not familiar with the stuff). Or maybe I should start by comparing the compilation flags of the two PyTorch versions. I don’t have the time, so I give up.</p><p>Oh, and lastly, <code>strace</code> is always our friend.</p><br><blockquote><p class="cc"><b>Author:</b> hsfzxjy.<br><b>Link:</b> <span class="cc-link"></span>.<br><b>License:</b> <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a>.<br>All rights reserved by the author.<br>Commercial use of this post in any form is <b>NOT</b> permitted.<br>Non-commercial use of this post should be attributed with this block of text.</p></blockquote><script>!function(){var n=document.querySelector("span.cc-link");n&&(n.innerHTML='<a href="'+location.href+'">'+location.href+"</a>")}()</script></div><div class="post__tags"></div><div class="post-nav"><a href="/extending-hexo-preface/" class="pre">«[Extending Hexo For My Site] Part 0 - Preface</a><a href="/internet-is-not-liberal/" class="next">不自由的互联网»</a></div><div id="disqus_thread"><div id="no-comment"><h2>OOPS!</h2><span>A comment box should be right here...</span><span>But it was gone due to network issues :-(</span><span>If you want to leave comments, make sure you have access to&nbsp;<a target="_blank" rel="noopener" href="https://disqus.com">disqus.com</a>.</span></div><script>var disqus_shortname="hsfzxjy",disqus_identifier="tensor-cuda-hang/",disqus_title="Debug a 'torch.tensor(1).cuda()' hanging",disqus_url="https://i.hsfzxjy.site/tensor-cuda-hang/";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.defer=!0,e.src="https://"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("body")[0]||document.getElementsByTagName("head")[0]).appendChild(e),e.onerror=function(){document.getElementById("no-comment").classList.add("show")}}()</script><script id="dsq-count-scr" src="//hsfzxjy.disqus.com/count.js" async defer></script></div></div></main><section class="aside__group"><span class="aside__btn"><div lang="zh" class="github-btn"><a href="#" rel="noopener noreferrer" target="_blank" class="gh-btn"><span class="gh-ico"></span><span class="gh-text">FOLLOW ME</span></a><a href="#" rel="noopener noreferrer" target="_blank" class="gh-count"></a></div><script>window.GH_BUTTON={username:"hsfzxjy"}</script></span><aside class="aside__left"><div class="aside__menuList"><span class="aside__menuList-item__icon"><i class="icon-home"></i></span><a href="/" class="aside__menuList-item"><span lang="zh" class="font__ui">首页 / Home</span></a><span class="aside__menuList-item__icon current"><i class="icon-embed2"></i></span><a href="/categories/Tech/" class="aside__menuList-item current"><span lang="zh" class="font__ui">科技 / Tech</span></a><span class="aside__menuList-item__icon"><i class="icon-android"></i></span><a href="/categories/Soliloquy/" class="aside__menuList-item"><span lang="zh" class="font__ui">呓语 / Soliloquy</span></a><span class="aside__menuList-item__icon"><i class="icon-leaf"></i></span><a href="/categories/Life/" class="aside__menuList-item"><span lang="zh" class="font__ui">生活 / Life</span></a><span class="aside__menuList-item__icon"><i class="icon-bookmarks"></i></span><a href="/categories/Memo/" class="aside__menuList-item"><span lang="zh" class="font__ui">速记 / Memo</span></a><span class="aside__menuList-item__icon"><i class="icon-books"></i></span><a href="/categories/Series/" class="aside__menuList-item"><span lang="zh" class="font__ui">连载 / Series</span></a><span class="aside__menuList-item__icon"><i class="icon-sigma"></i></span><a href="/works/" class="aside__menuList-item"><span lang="zh" class="font__ui">项目 / Projects</span></a><span class="aside__menuList-item__icon"><i class="icon-earth"></i></span><a href="/links/" class="aside__menuList-item"><span lang="zh" class="font__ui">友链 / Links</span></a><span class="aside__menuList-item__icon"><i class="icon-wink"></i></span><a href="/about/" class="aside__menuList-item"><span lang="zh" class="font__ui">关于 / About</span></a><span class="aside__menuList-item__icon"><i class="icon-history"></i></span><a href="/aggr/" class="aside__menuList-item"><span lang="zh" class="font__ui">索引 / Index</span></a><span class="aside__menuList-item__icon"><i class="icon-rss2"></i></span><a href="/rss.xml" class="aside__menuList-item"><span lang="zh" class="font__ui">订阅 / RSS</span></a></div></aside><aside class="aside__right"><div id="toc" lang="en" class="font__body"><div class="toc-toggler"></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#the-problem"><span class="toc-number">1.</span> <span class="toc-text">The Problem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-1-find-out-the-incorrect-arguments"><span class="toc-number">2.</span> <span class="toc-text">Step 1: Find out the incorrect arguments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-2-find-out-the-trapped-io"><span class="toc-number">3.</span> <span class="toc-text">Step 2: Find out the trapped IO</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-3-whos-performing-the-io"><span class="toc-number">4.</span> <span class="toc-text">Step 3: Who’s performing the IO?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cache-stored-on-a-slow-network-share"><span class="toc-number">4.1.</span> <span class="toc-text">Cache stored on a Slow Network Share</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#epilogue"><span class="toc-number">5.</span> <span class="toc-text">Epilogue</span></a></li></ol></div></div></aside></section><div id="footer" style="text-align:center" lang="zh" class="font__ui">© <a href="/" rel="nofollow">hsfzxjy 的博客.</a>&nbsp;Powered by&nbsp;<a rel="nofollow" target="_blank" href="https://hexo.io">Hexo.</a>&nbsp;<a rel="nofollow" target="_blank" href="https://github.com/hsfzxjy/byak-hexo">Theme</a>&nbsp;by&nbsp;<a rel="nofollow" target="_blank" href="https://github.com/hsfzxjy">hsfzxjy</a>.<div style="margin-top:10px"><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011202001249" style="display:inline-block;text-decoration:none;height:20px;line-height:20px"><img src="/img/beian.png" style="float:left" loading="lazy"><span style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#939393">粤公网安备44011202001249号</span></a><a target="_blank" style="display:inline-block;text-decoration:none;height:20px;line-height:20px" href="http://beian.miit.gov.cn/"><span style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#939393">粤ICP备2020075702号-1</span></a></div></div></body><script src="/dist/js/main.js" async defer></script></html>